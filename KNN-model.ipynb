{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/A/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x112332630>: 100%|██████████| 3000/3000 [00:05<00:00, 562.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/B/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111F9BAC8>: 100%|██████████| 3000/3000 [00:06<00:00, 492.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x112114978>:   0%|          | 4/3000 [00:00<02:35, 19.22 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/C/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1123DF8D0>: 100%|██████████| 3000/3000 [00:05<00:00, 508.31 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/D/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111E84358>: 100%|██████████| 3000/3000 [00:05<00:00, 519.19 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/E/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111FC9048>: 100%|██████████| 3000/3000 [00:06<00:00, 447.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x11201C080>:   0%|          | 3/3000 [00:00<03:09, 15.79 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/F/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1119CD908>: 100%|██████████| 3000/3000 [00:05<00:00, 524.78 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/G/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1118CA9E8>: 100%|██████████| 3000/3000 [00:05<00:00, 545.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111916EB8>:   0%|          | 3/3000 [00:00<05:14,  9.52 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/H/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111932B38>: 100%|██████████| 3000/3000 [00:05<00:00, 537.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/I/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x10EBE7A90>: 100%|██████████| 3000/3000 [00:05<00:00, 550.55 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/J/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111B160F0>: 100%|██████████| 3000/3000 [00:05<00:00, 564.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/K/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x112168908>: 100%|██████████| 3000/3000 [00:05<00:00, 556.92 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/L/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111BF04A8>: 100%|██████████| 3000/3000 [00:05<00:00, 558.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/M/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111C3CAC8>: 100%|██████████| 3000/3000 [00:05<00:00, 566.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1118DCC88>:   0%|          | 4/3000 [00:00<02:40, 18.61 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/N/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111C79F60>: 100%|██████████| 3000/3000 [00:05<00:00, 556.30 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/O/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1117894A8>: 100%|██████████| 3000/3000 [00:05<00:00, 555.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1123C79E8>:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/P/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111C455C0>: 100%|██████████| 3000/3000 [00:05<00:00, 576.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/Q/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x112328208>: 100%|██████████| 3000/3000 [00:05<00:00, 580.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/R/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111ADD5C0>: 100%|██████████| 3000/3000 [00:05<00:00, 574.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/S/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111D83240>: 100%|██████████| 3000/3000 [00:05<00:00, 560.35 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/T/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111FFC240>: 100%|██████████| 3000/3000 [00:05<00:00, 561.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x11176B358>:   0%|          | 4/3000 [00:00<03:03, 16.29 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/U/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111F712B0>: 100%|██████████| 3000/3000 [00:05<00:00, 559.55 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/V/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1118E4438>: 100%|██████████| 3000/3000 [00:05<00:00, 541.42 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/W/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111FAA160>: 100%|██████████| 3000/3000 [00:05<00:00, 587.63 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/X/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111D6CC88>: 100%|██████████| 3000/3000 [00:05<00:00, 575.35 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/Y/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111F1A0B8>: 100%|██████████| 3000/3000 [00:05<00:00, 596.94 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/Z/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111D179E8>: 100%|██████████| 3000/3000 [00:05<00:00, 586.70 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/space/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x1120A9F98>: 100%|██████████| 3000/3000 [00:05<00:00, 585.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/nothing/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x111D1D748>: 100%|██████████| 3000/3000 [00:05<00:00, 586.35 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/3000 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 3000 image(s) found.\n",
      "Output directory set to /Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/del/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=120x120 at 0x11209F4E0>: 100%|██████████| 3000/3000 [00:05<00:00, 580.91 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "#import data(training and test) and split then into training part and validation part\n",
    "from PIL import Image\n",
    "import Augmentor as ag\n",
    "import glob \n",
    "\n",
    "file_label = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', \n",
    "              'O', 'P', 'Q', 'R','S','T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space', 'nothing', 'del']\n",
    "\n",
    "\n",
    "#method-1 Center cropping\n",
    "for i in file_label:\n",
    "    file_path = '/Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/' + i\n",
    "    for filename in glob.glob(file_path):\n",
    "        s = ag.Pipeline(filename)\n",
    "        s.crop_centre(probability = 1, percentage_area = 0.6)\n",
    "        s.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import torchvision \n",
    "\n",
    "def load_image(file_name):\n",
    "    img = Image.open(file_name)\n",
    "    #img = img.convert('1')\n",
    "    img = torchvision.transforms.functional.resize(img, 28, interpolation=2)\n",
    "    img = np.array(img,np.float64)\n",
    "    #print(img)\n",
    "    data = img[:,:,0]\n",
    "    #change 28 x 28 to 784 x1 2d array \n",
    "    data = data.reshape(-1)\n",
    "    #data = data[np.newaxis, :]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64800, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "y_label = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', \n",
    "           'O', 'P', 'Q', 'R','S','T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space', 'nothing', 'del']\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(y_label)):\n",
    "    path = '/Users/qintaoying/Desktop/STAT-479/GP/asl-alphabet/asl_alphabet_train/'+ y_label[i] +'/output/*.jpg'\n",
    "    for filename in glob.glob(path):\n",
    "        im = load_image(filename)\n",
    "        x.append(im)\n",
    "        y.append(i)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x,y = shuffle_arrays_unison((x, y), random_seed=1)\n",
    "X_train, y_train = x[:64800], y[:64800]\n",
    "X_test, y_test = x[64800:], y[64800:]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pipeline to selcet the best model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     KNeighborsClassifier()\n",
    ")\n",
    "\n",
    "param_grid = [{'kneighborsclassifier__n_neighbors': list(range(1, 16)),\n",
    "               'kneighborsclassifier__p': [1, 2]}]\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator = pipe, \n",
    "                  param_grid = param_grid, \n",
    "                  iid=False,\n",
    "                  n_jobs=-1,\n",
    "                  refit=True,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))\n",
    "print('Best Params: %s' % (gs.best_params_))\n",
    "print('Test Accuracy: %.2f%%' % (gs.best_estimator_.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the decision region\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = gs.best_params)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "plot_decision_regions(X_train, y_train, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate the generalized performance using the 0.632 bootstrap\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "scores = bootstrap_point632_score(KNeighborsClassifier(n_neighbors = 5, p = 2),X_test,y_test,\n",
    "                                  n_splits = 200, random_seed = 1)\n",
    "\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "##confidence area\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct a multiclass confusion matrix here\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def confusion_matrix_multiclass(y_true, y_predicted):\n",
    "\n",
    "    matrix = np.zeros(25).reshape(5, 5).astype(int)\n",
    "    for i,j in zip(y_true, y_predicted):\n",
    "        if i == j:\n",
    "            matrix[i, i] += 1\n",
    "        else:\n",
    "            matrix[i, j] += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "y_true =      [1, 1, 1, 1, 0, 2, 0, 3, 4, 2, 1, 2, 2, 1, 2, 1, 0, 1, 1, 0]\n",
    "y_predicted = [1, 0, 1, 1, 0, 2, 1, 3, 4, 2, 2, 0, 2, 1, 2, 1, 0, 3, 1, 1]\n",
    "\n",
    "result_matrix = confusion_matrix_multiclass(y_true, y_predicted)\n",
    "result_matrix\n",
    "\n",
    "#plot the confussion matrix\n",
    "from helper import plot_confusion_matrix\n",
    "\n",
    "\n",
    "plot_confusion_matrix(result_matrix)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
